server:
  port: ${FILTERING_SERVICE_PORT:0}

logging:
  level:
    root: ${APP_SERVICE_ROOT_LOG_LEVEL:INFO}
    org.springframework: ${APP_SERVICE_SPRING_LOG_LEVEL:INFO}

spring:
  config:
    import: optional:file:.env[.properties]

  application:
    name: ${FILTERING_SERVICE_NAME:filtering-service}

  data:
    mongodb:
      uri: ${FILTERING_SERVICE_MONGODB_URI:uri}
      database: ${FILTERING_SERVICE_MONGODB_DATABASE:filtering-service-db}
      auto-index-creation: true
    redis:
      host: ${FILTERING_SERVICE_DATA_REDIS_HOST:localhost}
      port: ${FILTERING_SERVICE_DATA_REDIS_PORT:14218}
      username: ${FILTERING_SERVICE_DATA_REDIS_USERNAME:u1}
      password: ${FILTERING_SERVICE_DATA_REDIS_PASSWORD:p1}

  threads:
    virtual:
      enabled: true

filter:
  criteria:
    title: ${FILTERING_SERVICE_FILTER_CRITERIA_ONLY_FOR_TITLE:false}

kafka:
  topic:
    in: ${CLOUD_KAFKA_USERNAME}-${FILTERING_SERVICE_TOPIC_IN:filtering-topic}
    out: ${CLOUD_KAFKA_USERNAME}-${FILTERING_SERVICE_TOPIC_OUT:storage-topic}
  server:
    bootstrapServer: ${CLOUD_KAFKA_BROKER_URL}
    propertySecurityProtocol: SASL_SSL
    propertySaslMechanism: SCRAM-SHA-256
    propertySaslJaasConfig: org.apache.kafka.common.security.scram.ScramLoginModule required username="${CLOUD_KAFKA_USERNAME}" password="${CLOUD_KAFKA_PASSWORD}";
  producer:
    keySerializer: org.apache.kafka.common.serialization.StringSerializer
    valueSerializer: org.springframework.kafka.support.serializer.JsonSerializer
    propertyEnableIdempotence: false
    propertySpringJsonAddTypeHeaders: false
  consumer:
    autoOffsetReset: earliest
    groupId: ${CLOUD_KAFKA_USERNAME}-consumers
    keyDeserializer: org.apache.kafka.common.serialization.StringDeserializer
    valueDeserializer: org.springframework.kafka.support.serializer.JsonDeserializer
    propertySpringJsonTrustedPackages: '*'

management:
  endpoints:
    web:
      exposure:
        include:
          - health